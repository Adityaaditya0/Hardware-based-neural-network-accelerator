# Hardware-based-neural-network-accelerator
It is sparsity-aware, meaning it skips computations when input activations are zero, which reduces unnecessary operations and improves performanceâ€”a common optimization in AI/ML hardware accelerators.
